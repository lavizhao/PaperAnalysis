#问答系统

**注：**这里单独说的是问答，不是MC，MC如果写的话，单独写， 主要我也是菜，不懂
**注1：**这里面基本不讲KBQA，因为KBQA没啥可讲的
**注2：**这里面基本以谷歌等确实的行家为主，垃圾论文能不贴就不贴了

## YN（YES/NO)

[BERT+NLI transfer](https://arxiv.org/pdf/1905.10044.pdf "google yn")

谷歌是非的文章, 自己搞了个数据集，九千train、三千dev、三千test，选用谷歌大搜top5结果。

最坏结果是62%，BERT微调不出意外能达到77%，加入了Multi-NLI 数据集训练结果能调整到80%。

里面有一个有意思的结论是，Muiti-NLI把无关句子去了之后，效果提升没那么显著，这个结论其实和我之前的DNN-QA结论是大致类似的。

还有就是用同样有是非的Macro，效果并没有提升，作者说是因为macro标注不均衡的作用。

**总结：**结论其实挺有意思的，做阅读理解的数据做预训练没用，做句子关系的数据集反倒能有提高。

